{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nestedtensor\n",
    "from IPython.display import Markdown, display\n",
    "def print_eval(s):\n",
    "    colorS = \"<span style='color:darkred'>$ {}</span>\".format(s)\n",
    "    display(Markdown('**{}**'.format(colorS))) \n",
    "    print('{}\\n'.format(str(eval(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time_module\n",
    "def time(fn):\n",
    "    t0 = time_module.time()\n",
    "    count = 0\n",
    "    past = 0\n",
    "    while past < 10.0:\n",
    "        fn()\n",
    "        past = time_module.time() - t0\n",
    "        count += 1\n",
    "    past = past / count\n",
    "    return \"average {:2.4f}ms based on {} samples\".format(past * 1000, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensors(num_tensor, vocab_size):\n",
    "    sentence_lengths = torch.normal(75.0, 10.0, size=(num_tensor,)).long()\n",
    "    return [(torch.rand(l) * vocab_size).long() for l in sentence_lengths]\n",
    "\n",
    "def generate_text(text):\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text.to(torch.int64), offsets\n",
    "\n",
    "class TextSentiment(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        emb = self.embedding(text, offsets)\n",
    "        return self.fc(emb)\n",
    "\n",
    "# THIS IS TEMPORARILY DISABLED\n",
    "# vocab_size = 10000\n",
    "# model = TextSentiment(10000, 256, 5)\n",
    "# tensors = generate_tensors(16, 10000)\n",
    "# text, offsets = generate_text(tensors)\n",
    "# nt_text = nestedtensor.nested_tensor(tensors)\n",
    "\n",
    "# print_eval(\"time(lambda: model(text, offsets))\")\n",
    "# print_eval(\"time(lambda: model(nt_text, None))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ images.numel()</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ time(lambda: model(images))</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 55.8146ms based on 180 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "images = torch.rand(128, 3, 40, 50)\n",
    "print_eval(\"images.numel()\")\n",
    "print_eval(\"time(lambda: model(images))\")\n",
    "\n",
    "# THIS IS TEMPORARILY DISABLED\n",
    "# nested_images = nestedtensor.nested_tensor(torch.rand(128, 3, 40, 50).unbind())\n",
    "# print_eval(\"time(lambda: model(nested_images))\")\n",
    "\n",
    "# # There is still about a 10x gap in performance, which however\n",
    "# # can be significantly allieviated via custom code (e.g. using im2col).\n",
    "# images = [torch.rand(3, (i * 16) % 40 + 40, (i * 16) % 50 + 40) for i in range(64)]\n",
    "# nested_irregular_images = nestedtensor.nested_tensor(images)\n",
    "# print_eval(\"nested_irregular_images.numel()\")\n",
    "# print_eval(\"nested_irregular_images.size()\")\n",
    "# print_eval(\"time(lambda: model(nested_irregular_images))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TEMPORARILY DISABLED\n",
    "\n",
    "# def generate_tensors(num_tensor, num_features):\n",
    "#     sentence_lengths = torch.normal(75.0, 10.0, size=(num_tensor,)).long()\n",
    "#     return [torch.rand(l.item(), num_features) for l in sentence_lengths]\n",
    "\n",
    "# tensors = generate_tensors(32, 256)\n",
    "# nt_text = nestedtensor.nested_tensor(tensors)\n",
    "# text = torch.rand(32, 75, 256)\n",
    "\n",
    "# h0 = torch.randn(6, len(nt_text), 512)\n",
    "# c0 = torch.randn(6, len(nt_text), 512)\n",
    "# print_eval(\"nt_text.nested_size(1)\")\n",
    "# print_eval(\"nt_text.numel()\")\n",
    "# print_eval(\"text.numel()\")\n",
    "# print_eval(\"time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(nt_text, (h0, c0)))\")\n",
    "# print_eval(\"time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(text, (h0, c0)))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
