{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This is currently disabled!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92550ae70912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is currently disabled!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: This is currently disabled!"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import io\n",
    "import tarfile\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import nestedtensor\n",
    "\n",
    "URL = \"https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\"\n",
    "\n",
    "raise Exception(\"This example notebook is temporarily disabled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = namedtuple('Point', 'label text')\n",
    "\n",
    "def get_data(URL):\n",
    "    r = requests.get(URL)\n",
    "    file_like_object = io.BytesIO(r.content)\n",
    "    tar = tarfile.open(fileobj=file_like_object)\n",
    "    d = {}\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile() and member.name.endswith('csv'):\n",
    "            k = 'train' if 'train' in member.name else 'test'\n",
    "            d[k] = tar.extractfile(member)\n",
    "    return d\n",
    "\n",
    "\n",
    "def preprocess(iterator):\n",
    "    def _preprocess(line):\n",
    "        line = line.decode('UTF-8')\n",
    "        line = line.lower()\n",
    "        line = re.sub(r'[^0-9a-zA-Z,\\s]', \"\", line)\n",
    "        line = line.split(',')\n",
    "        label = int(line[0]) - 1\n",
    "        text = (\" \".join(line[1:])).split()\n",
    "        if len(line) > 2:\n",
    "            return Point(label=label, text=text)\n",
    "    for line in iterator:\n",
    "        yield _preprocess(line)\n",
    "\n",
    "\n",
    "def build_vocab(iterator):\n",
    "    counter = Counter()\n",
    "    labels = set()\n",
    "    for point in iterator:\n",
    "        counter.update(point.text)\n",
    "        labels.add(point.label)\n",
    "    vocab = {}\n",
    "    for i, (word, count) in enumerate(counter.most_common()):\n",
    "        vocab[word] = i\n",
    "\n",
    "    return vocab, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(URL)\n",
    "data = {k: list(preprocess(v)) for (k, v) in data.items()}\n",
    "vocab, labels = build_vocab(data['train'])\n",
    "UNK = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        return self.fc(self.embedding(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 10\n",
    "model = TextSentiment(len(vocab) + 1, embed_dim, len(labels)).cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data):\n",
    "    data = torch.nested_tensor(\n",
    "        [torch.tensor(list(map(lambda x: vocab.get(x, UNK), tokens))) for tokens in data])\n",
    "    return data\n",
    "\n",
    "def yield_data_futures(data):\n",
    "    random.shuffle(data)\n",
    "    labels = []\n",
    "    batch_data = []\n",
    "    futures = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        for i, point in enumerate(data):\n",
    "            # Stop accumulating lines of text once we reach 4000 tokens or more\n",
    "            # This yields variable batch sizes, but with consistent memory pressure\n",
    "            if sum(map(len, batch_data), 0) < 10000:\n",
    "                labels.append(point.label)\n",
    "                batch_data.append(point.text)\n",
    "            else:\n",
    "                if len(futures) < 40:\n",
    "                    futures.append((torch.tensor(labels), executor.submit(create_batch, batch_data)))\n",
    "                else:\n",
    "                    yield futures[0]\n",
    "                    futures = futures[1:]\n",
    "                labels = []\n",
    "                batch_data = []\n",
    "\n",
    "    for future in futures:\n",
    "        yield future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = sum(map(lambda x: len(x.text), data['train']))\n",
    "print(\"Total number of tokens: {}\".format(num_tokens))\n",
    "for epoch in range(5):\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    for labels, future in yield_data_futures(data['train']):\n",
    "        batch = future.result()\n",
    "        labels = labels.to('cuda', non_blocking=True)\n",
    "        batch = batch.to('cuda', non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 16 == 1:\n",
    "            sys.stderr.write(\n",
    "                \"\\rtime: {:3.0f}s epoch: {:3.0f} lr: {:3.6f} loss: {:3.6f}\".format(\n",
    "                    time.time() - t0, \n",
    "                    epoch, \n",
    "                    scheduler.get_lr()[0],\n",
    "                    loss, \n",
    "                )\n",
    "            )\n",
    "            sys.stderr.flush()\n",
    "        i += batch.numel()\n",
    "    scheduler.step()\n",
    "    sys.stderr.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [(tb[0], model(tb[1].result().to('cuda')).argmax(1).cpu()) for tb in yield_data_futures(data['test'])]\n",
    "predictions = torch.cat(list(map(lambda x: x[1], output)))\n",
    "labels = torch.cat(list(map(lambda x: x[0], output)))\n",
    "\n",
    "print(\"Test accuracy: {}\".format((labels == predictions).sum().float() / len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
